
---
# Source: prometheus/templates/alertmanager-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "alertmanager"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-alertmanager
data:
  alertmanager.yml: |-
    global:
      # slack_api_url: ''
  
    receivers:
      - name: default-receiver
        # slack_configs:
        #  - channel: '@you'
        #    send_resolved: true
  
    route:
      group_wait: 10s
      group_interval: 5m
      receiver: default-receiver
      repeat_interval: 3h
---
# Source: prometheus/templates/server-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "server"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-server
data:
  alerts: ""
  prometheus.yml: |-
    rule_files:
      - /etc/config/rules
      - /etc/config/alerts
  
    scrape_configs:
      - job_name: prometheus
        static_configs:
          - targets:
            - localhost:9090
  
      # A scrape configuration for running Prometheus on a Kubernetes cluster.
      # This uses separate scrape configs for cluster components (i.e. API server, node)
      # and services to allow each to use different authentication configs.
      #
      # Kubernetes labels will be added as Prometheus labels on metrics via the
      # `labelmap` relabeling action.
  
      # Scrape config for API servers.
      #
      # Kubernetes exposes API servers as endpoints to the default/kubernetes
      # service so this uses `endpoints` role and uses relabelling to only keep
      # the endpoints associated with the default/kubernetes service using the
      # default named port `https`. This works for single API server deployments as
      # well as HA API server deployments.
      - job_name: 'kubernetes-apiservers'
  
        kubernetes_sd_configs:
          - role: endpoints
  
        # Default to scraping over https. If required, just disable this or change to
        # `http`.
        scheme: https
  
        # This TLS & bearer token file config is used to connect to the actual scrape
        # endpoints for cluster components. This is separate to discovery auth
        # configuration because discovery & scraping are two separate concerns in
        # Prometheus. The discovery auth config is automatic if Prometheus runs inside
        # the cluster. Otherwise, more config options have to be provided within the
        # <kubernetes_sd_config>.
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          # If your node certificates are self-signed or use a different CA to the
          # master CA, then disable certificate verification below. Note that
          # certificate verification is an integral part of a secure infrastructure
          # so this should only be disabled in a controlled environment. You can
          # disable certificate verification by uncommenting the line below.
          #
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  
        # Keep only the default/kubernetes service endpoints for the https port. This
        # will add targets for each API server which Kubernetes adds an endpoint to
        # the default/kubernetes service.
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https
  
      - job_name: 'kubernetes-nodes'
  
        # Default to scraping over https. If required, just disable this or change to
        # `http`.
        scheme: https
  
        # This TLS & bearer token file config is used to connect to the actual scrape
        # endpoints for cluster components. This is separate to discovery auth
        # configuration because discovery & scraping are two separate concerns in
        # Prometheus. The discovery auth config is automatic if Prometheus runs inside
        # the cluster. Otherwise, more config options have to be provided within the
        # <kubernetes_sd_config>.
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          # If your node certificates are self-signed or use a different CA to the
          # master CA, then disable certificate verification below. Note that
          # certificate verification is an integral part of a secure infrastructure
          # so this should only be disabled in a controlled environment. You can
          # disable certificate verification by uncommenting the line below.
          #
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  
        kubernetes_sd_configs:
          - role: node
  
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
  
      # Scrape config for service endpoints.
      #
      # The relabeling allows the actual service scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`
      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
      # to set this to `https` & most likely set the `tls_config` of the scrape config.
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: If the metrics are exposed on a different port to the
      # service then set this appropriately.
      - job_name: 'kubernetes-service-endpoints'
  
        kubernetes_sd_configs:
          - role: endpoints
  
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: (.+)(?::\d+);(\d+)
            replacement: $1:$2
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_name
  
      - job_name: 'prometheus-pushgateway'
        honor_labels: true
  
        kubernetes_sd_configs:
          - role: service
  
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
            action: keep
            regex: pushgateway
  
      # Example scrape config for probing services via the Blackbox Exporter.
      #
      # The relabeling allows the actual service scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/probe`: Only probe services that have a value of `true`
      - job_name: 'kubernetes-services'
  
        metrics_path: /probe
        params:
          module: [http_2xx]
  
        kubernetes_sd_configs:
          - role: service
  
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
            action: keep
            regex: true
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            target_label: kubernetes_name
  
      # Example scrape config for pods
      #
      # The relabeling allows the actual pod scrape endpoint to be configured via the
      # following annotations:
      #
      # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.
      - job_name: 'kubernetes-pods'
  
        kubernetes_sd_configs:
          - role: pod
  
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: (.+):(?:\d+);(\d+)
            replacement: ${1}:${2}
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
  rules: ""
---
# Source: prometheus/templates/alertmanager-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "alertmanager"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-alertmanager
spec:
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 9093
  selector:
    app: prometheus
    component: "alertmanager"
    release: inclined-otter
  type: "NodePort"
---
# Source: prometheus/templates/kube-state-metrics-svc.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
    
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "kube-state-metrics"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-kube-state-metrics
spec:
  clusterIP: None
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8080
  selector:
    app: prometheus
    component: "kube-state-metrics"
    release: inclined-otter
  type: "ClusterIP"
---
# Source: prometheus/templates/node-exporter-service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
    
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "node-exporter"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-node-exporter
spec:
  clusterIP: None
  ports:
    - name: metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
  selector:
    app: prometheus
    component: "node-exporter"
    release: inclined-otter
  type: "ClusterIP"
---
# Source: prometheus/templates/server-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "server"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-server
spec:
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 9090
  selector:
    app: prometheus
    component: "server"
    release: inclined-otter
  type: "NodePort"
---
# Source: prometheus/templates/node-exporter-daemonset.yaml
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "node-exporter"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-node-exporter
spec:
  template:
    metadata:
      labels:
        app: prometheus
        component: "node-exporter"
        release: inclined-otter
    spec:
      serviceAccountName: "default"
      containers:
        - name: prometheus-node-exporter
          image: "prom/node-exporter:v0.15.0"
          imagePullPolicy: "IfNotPresent"
          args:
            - --path.procfs=/host/proc
            - --path.sysfs=/host/sys
            - --collector.textfile.directory=/srv/textfile_collector
          ports:
            - name: metrics
              containerPort: 9100
              hostPort: 9100
          resources:
            {}
            
          volumeMounts:
            - name: proc
              mountPath: /host/proc
              readOnly:  true
            - name: sys
              mountPath: /host/sys
              readOnly: true
            - name: textfile-dir
              mountPath: /srv/textfile_collector
              readOnly: true
      hostNetwork: true
      hostPID: true
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: sys
          hostPath:
            path: /sys
        - name: textfile-dir
          hostPath:
            path: /var/lib/node_exporter/textfile_collector
---
# Source: prometheus/templates/alertmanager-deployment.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "alertmanager"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-alertmanager
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
        component: "alertmanager"
        release: inclined-otter
    spec:
      serviceAccountName: "default"
      containers:
        - name: prometheus-alertmanager
          image: "prom/alertmanager:v0.9.1"
          imagePullPolicy: "IfNotPresent"
          env:
          args:
            - --config.file=/etc/config/alertmanager.yml
            - --storage.path=/data
          ports:
            - containerPort: 9093
          readinessProbe:
            httpGet:
              path: /#/status
              port: 9093
            initialDelaySeconds: 30
            timeoutSeconds: 30
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: "/data"
              subPath: ""

        - name: prometheus-alertmanager-configmap-reload
          image: "jimmidyson/configmap-reload:v0.1"
          imagePullPolicy: "IfNotPresent"
          args:
            - --volume-dir=/etc/config
            - --webhook-url=http://localhost:9093/-/reload
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
              readOnly: true
      volumes:
        - name: config-volume
          configMap:
            name: inclined-otter-prometheus-alertmanager
        - name: storage-volume
          emptyDir: {}
---
# Source: prometheus/templates/kube-state-metrics-deployment.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "kube-state-metrics"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-kube-state-metrics
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
        component: "kube-state-metrics"
        release: inclined-otter
    spec:
      serviceAccountName: "default"
      containers:
        - name: prometheus-kube-state-metrics
          image: "gcr.io/google_containers/kube-state-metrics:v1.1.0-rc.0"
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: metrics
              containerPort: 8080
          resources:
            {}
---
# Source: prometheus/templates/server-deployment.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: prometheus
    chart: prometheus-4.6.10
    component: "server"
    heritage: Tiller
    release: inclined-otter
  name: inclined-otter-prometheus-server
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
        component: "server"
        release: inclined-otter
    spec:
      serviceAccountName: "default"
      containers:
        - name: prometheus-server-configmap-reload
          image: "jimmidyson/configmap-reload:v0.1"
          imagePullPolicy: "IfNotPresent"
          args:
            - --volume-dir=/etc/config
            - --webhook-url=http://localhost:9090/-/reload
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
              readOnly: true

        - name: prometheus-server
          image: "prom/prometheus:v1.8.1"
          imagePullPolicy: "IfNotPresent"
          args:
            - --alertmanager.url=http://inclined-otter-prometheus-alertmanager:80
            - --config.file=/etc/config/prometheus.yml
            - --storage.local.path=/data
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
          ports:
            - containerPort: 9090
          readinessProbe:
            httpGet:
              path: /status
              port: 9090
            initialDelaySeconds: 30
            timeoutSeconds: 30
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: /data
              subPath: ""
      terminationGracePeriodSeconds: 300
      volumes:
        - name: config-volume
          configMap:
            name: inclined-otter-prometheus-server
        - name: storage-volume
          emptyDir: {}
